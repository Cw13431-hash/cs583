{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygyfl-z7EyCq"
      },
      "source": [
        "# Programming Assignment: Build a CNN for image recognition.\n",
        "\n",
        "### Name: [Chenjing.Wang]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAM5cSGdEyCr"
      },
      "source": [
        "## 0. You will do the following:\n",
        "\n",
        "1. Read, complete, and run the code.\n",
        "\n",
        "2. **Make substantial improvements** to maximize the accuracy.\n",
        "    \n",
        "3. Convert the .IPYNB file to .HTML file.\n",
        "\n",
        "    * The HTML file must contain the code and the output after execution.\n",
        "    \n",
        "    * Missing **the output after execution** will not be graded.\n",
        "\n",
        "\n",
        "4. Upload the .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
        "\n",
        "4. On Canvas, submit the Google Drive/Dropbox/Github link to the HTML file.\n",
        "\n",
        "\n",
        "## Requirements:\n",
        "\n",
        "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
        "\n",
        "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
        "\n",
        "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
        "\n",
        "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
        "\n",
        "\n",
        "## Google Colab\n",
        "\n",
        "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
        "\n",
        "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
        "\n",
        "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
        "\n",
        "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FSiAL2mEyCs"
      },
      "source": [
        "## 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUst8vSrEyCt"
      },
      "source": [
        "### 1.1. Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F04XVg-QEyCt",
        "outputId": "528b57d1-a6bd-4300-b6a7-ee26e2ac66ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "shape of x_train: (50000, 32, 32, 3)\n",
            "shape of y_train: (50000, 1)\n",
            "shape of x_test: (10000, 32, 32, 3)\n",
            "shape of y_test: (10000, 1)\n",
            "number of classes: 10\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import cifar10\n",
        "import numpy\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('shape of x_train: ' + str(x_train.shape))\n",
        "print('shape of y_train: ' + str(y_train.shape))\n",
        "print('shape of x_test: ' + str(x_test.shape))\n",
        "print('shape of y_test: ' + str(y_test.shape))\n",
        "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfudP4y2EyCw"
      },
      "source": [
        "### 1.2. One-hot encode the labels\n",
        "\n",
        "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
        "\n",
        "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
        "\n",
        "2. Apply the function to ```y_train``` and ```y_test```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKNMgQHyEyCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf896b2-97af-4f9e-d9b9-04ed4f5873e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_train_vec: (50000, 10)\n",
            "Shape of y_test_vec: (10000, 10)\n",
            "[6]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "from keras.utils import to_categorical\n",
        "def to_one_hot(y, num_class=10):\n",
        "\n",
        "    to_one_hot = to_categorical(y, 10)\n",
        "    return to_one_hot\n",
        "\n",
        "y_train_vec = to_one_hot(y_train)\n",
        "y_test_vec = to_one_hot(y_test)\n",
        "\n",
        "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
        "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
        "\n",
        "print(y_train[0])\n",
        "print(y_train_vec[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HIiE8KdEyCy"
      },
      "source": [
        "#### Remark: the outputs should be\n",
        "* Shape of y_train_vec: (50000, 10)\n",
        "* Shape of y_test_vec: (10000, 10)\n",
        "* [6]\n",
        "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXAeaCKwEyCz"
      },
      "source": [
        "### 1.3. Randomly partition the training set to training and validation sets\n",
        "\n",
        "Randomly partition the 50K training samples to 2 sets:\n",
        "* a training set containing 40K samples\n",
        "* a validation set containing 10K samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GffZwqRbEyC0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ece9a6c-c417-443f-8909-7e4cf2f34f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_tr: (40000, 32, 32, 3)\n",
            "Shape of y_tr: (40000, 10)\n",
            "Shape of x_val: (10000, 32, 32, 3)\n",
            "Shape of y_val: (10000, 10)\n"
          ]
        }
      ],
      "source": [
        "rand_indices = numpy.random.permutation(50000)\n",
        "train_indices = rand_indices[0:40000]\n",
        "valid_indices = rand_indices[40000:50000]\n",
        "\n",
        "x_val = x_train[valid_indices, :]\n",
        "y_val = y_train_vec[valid_indices, :]\n",
        "\n",
        "x_tr = x_train[train_indices, :]\n",
        "y_tr = y_train_vec[train_indices, :]\n",
        "\n",
        "print('Shape of x_tr: ' + str(x_tr.shape))\n",
        "print('Shape of y_tr: ' + str(y_tr.shape))\n",
        "print('Shape of x_val: ' + str(x_val.shape))\n",
        "print('Shape of y_val: ' + str(y_val.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation"
      ],
      "metadata": {
        "id": "jaShs8z6bMxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# Data augmentation\n",
        "data_generator = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range=15,\n",
        "\n",
        "    width_shift_range=0.12,\n",
        "\n",
        "    height_shift_range=0.12,\n",
        "\n",
        "    horizontal_flip=True,\n",
        "\n",
        "    zoom_range=0.1,\n",
        "\n",
        "    brightness_range=[0.9,1.1],\n",
        "\n",
        "    shear_range=10,\n",
        "\n",
        "    channel_shift_range=0.1,\n",
        ")"
      ],
      "metadata": {
        "id": "hwS0f8HlbLq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfbyXL07EyC1"
      },
      "source": [
        "## 2. Build a CNN and tune its hyper-parameters\n",
        "\n",
        "1. Build a convolutional neural network model\n",
        "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
        "    * Do NOT use test data for hyper-parameter tuning!!!\n",
        "3. Try to achieve a validation accuracy as high as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxAyM-C4EyC1"
      },
      "source": [
        "### Remark:\n",
        "\n",
        "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
        "* Add more layers.\n",
        "* Use regularizations, e.g., dropout.\n",
        "* Use batch normalization."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This CNN is built using VGG16 without batch normalization and set epoch = 100(no fit result currently due to GPU limitation)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('shape of x_train: ' + str(x_train.shape))\n",
        "print('shape of y_train: ' + str(y_train.shape))\n",
        "print('shape of x_test: ' + str(x_test.shape))\n",
        "print('shape of y_test: ' + str(y_test.shape))\n",
        "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "def to_one_hot(y, num_class=10):\n",
        "\n",
        "    to_one_hot = to_categorical(y, 10)\n",
        "    return to_one_hot\n",
        "\n",
        "y_train_vec = to_one_hot(y_train)\n",
        "y_test_vec = to_one_hot(y_test)\n",
        "\n",
        "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
        "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
        "\n",
        "print(y_train[0])\n",
        "print(y_train_vec[0])\n",
        "\n",
        "rand_indices = numpy.random.permutation(50000)\n",
        "train_indices = rand_indices[0:40000]\n",
        "valid_indices = rand_indices[40000:50000]\n",
        "\n",
        "x_val = x_train[valid_indices, :]\n",
        "y_val = y_train_vec[valid_indices, :]\n",
        "\n",
        "x_tr = x_train[train_indices, :]\n",
        "y_tr = y_train_vec[train_indices, :]\n",
        "\n",
        "print('Shape of x_tr: ' + str(x_tr.shape))\n",
        "print('Shape of y_tr: ' + str(y_tr.shape))\n",
        "print('Shape of x_val: ' + str(x_val.shape))\n",
        "print('Shape of y_val: ' + str(y_val.shape))\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# Data augmentation\n",
        "data_generator = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range=15,\n",
        "\n",
        "    width_shift_range=0.12,\n",
        "\n",
        "    height_shift_range=0.12,\n",
        "\n",
        "    horizontal_flip=True,\n",
        "\n",
        "    zoom_range=0.1,\n",
        "\n",
        "    brightness_range=[0.9,1.1],\n",
        "\n",
        "    shear_range=10,\n",
        "\n",
        "    channel_shift_range=0.1,\n",
        ")\n",
        "\n",
        "val_generator = data_generator.flow(x_val, y_val, batch_size = 100)\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,BatchNormalization, Dropout\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "from keras import optimizers\n",
        "\n",
        "learning_rate = 0.001#(after tunning)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=learning_rate),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(data_generator.flow(x_tr, y_tr, batch_size=500),\n",
        "                    epochs=100,\n",
        "                    validation_data=val_generator,\n",
        "                    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H0gUAFf8D4Pn",
        "outputId": "e30fcdcf-7538-4aaa-f8e6-0e7afc379ab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 0us/step\n",
            "shape of x_train: (50000, 32, 32, 3)\n",
            "shape of y_train: (50000, 1)\n",
            "shape of x_test: (10000, 32, 32, 3)\n",
            "shape of y_test: (10000, 1)\n",
            "number of classes: 10\n",
            "Shape of y_train_vec: (50000, 10)\n",
            "Shape of y_test_vec: (10000, 10)\n",
            "[6]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "Shape of x_tr: (40000, 32, 32, 3)\n",
            "Shape of y_tr: (40000, 10)\n",
            "Shape of x_val: (10000, 32, 32, 3)\n",
            "Shape of y_val: (10000, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m590,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m590,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m525,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m10,250\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,250</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,345,258\u001b[0m (31.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,345,258</span> (31.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,345,258\u001b[0m (31.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,345,258</span> (31.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m21/80\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28:00\u001b[0m 28s/step - acc: 0.0989 - loss: 2.3028"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwYDg3fgEyC2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d4cee7ed-f7b8-418a-98ea-7c76388baed1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m590,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m590,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m525,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m10,250\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,250</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,352,810\u001b[0m (31.86 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,352,810</span> (31.86 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,349,034\u001b[0m (31.85 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,349,034</span> (31.85 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,776\u001b[0m (14.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,776</span> (14.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Improvement with batcn normalization.\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,BatchNormalization, Dropout\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYVk_KDqEyC2"
      },
      "outputs": [],
      "source": [
        "\n",
        "from keras import optimizers\n",
        "\n",
        "learning_rate = 1E-25 #(using this learning_rate, the programming converges too slow.)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=learning_rate),\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zf977kWbEyC2",
        "outputId": "8be8c0be-c64d-4242-ead3-ac0093207dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "shape of x_train: (50000, 32, 32, 3)\n",
            "shape of y_train: (50000, 1)\n",
            "shape of x_test: (10000, 32, 32, 3)\n",
            "shape of y_test: (10000, 1)\n",
            "number of classes: 10\n",
            "Shape of y_train_vec: (50000, 10)\n",
            "Shape of y_test_vec: (10000, 10)\n",
            "[6]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "Shape of x_tr: (40000, 32, 32, 3)\n",
            "Shape of y_tr: (40000, 10)\n",
            "Shape of x_val: (10000, 32, 32, 3)\n",
            "Shape of y_val: (10000, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m590,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m590,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m525,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m10,250\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,250</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,352,810\u001b[0m (31.86 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,352,810</span> (31.86 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,349,034\u001b[0m (31.85 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,349,034</span> (31.85 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,776\u001b[0m (14.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,776</span> (14.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 501ms/step - acc: 0.1349 - loss: 3.3276 - val_acc: 0.1007 - val_loss: 2.9567\n",
            "Epoch 2/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 460ms/step - acc: 0.2338 - loss: 2.0802 - val_acc: 0.1007 - val_loss: 2.9499\n",
            "Epoch 3/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 484ms/step - acc: 0.3720 - loss: 1.7115 - val_acc: 0.1580 - val_loss: 2.2885\n",
            "Epoch 4/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 458ms/step - acc: 0.4623 - loss: 1.4797 - val_acc: 0.1777 - val_loss: 2.3195\n",
            "Epoch 5/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 467ms/step - acc: 0.5237 - loss: 1.3394 - val_acc: 0.3801 - val_loss: 1.7403\n",
            "Epoch 6/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 467ms/step - acc: 0.5727 - loss: 1.2192 - val_acc: 0.4957 - val_loss: 1.4414\n",
            "Epoch 7/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 469ms/step - acc: 0.6138 - loss: 1.1107 - val_acc: 0.5401 - val_loss: 1.3479\n",
            "Epoch 8/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 465ms/step - acc: 0.6279 - loss: 1.0747 - val_acc: 0.6046 - val_loss: 1.1421\n",
            "Epoch 9/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 457ms/step - acc: 0.6561 - loss: 1.0055 - val_acc: 0.6142 - val_loss: 1.1404\n",
            "Epoch 10/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 467ms/step - acc: 0.6750 - loss: 0.9551 - val_acc: 0.6762 - val_loss: 1.0511\n",
            "Epoch 11/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 467ms/step - acc: 0.6958 - loss: 0.9131 - val_acc: 0.7061 - val_loss: 0.9273\n",
            "Epoch 12/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 468ms/step - acc: 0.7121 - loss: 0.8580 - val_acc: 0.6836 - val_loss: 1.0082\n",
            "Epoch 13/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 464ms/step - acc: 0.7169 - loss: 0.8298 - val_acc: 0.7156 - val_loss: 0.9200\n",
            "Epoch 14/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 464ms/step - acc: 0.7334 - loss: 0.8008 - val_acc: 0.6967 - val_loss: 1.0003\n",
            "Epoch 15/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 462ms/step - acc: 0.7456 - loss: 0.7654 - val_acc: 0.6873 - val_loss: 0.9806\n",
            "Epoch 16/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 458ms/step - acc: 0.7548 - loss: 0.7452 - val_acc: 0.7234 - val_loss: 0.9324\n",
            "Epoch 17/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 462ms/step - acc: 0.7630 - loss: 0.7173 - val_acc: 0.7257 - val_loss: 0.8918\n",
            "Epoch 18/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 462ms/step - acc: 0.7675 - loss: 0.6984 - val_acc: 0.7272 - val_loss: 0.8006\n",
            "Epoch 19/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 465ms/step - acc: 0.7821 - loss: 0.6557 - val_acc: 0.6993 - val_loss: 0.8774\n",
            "Epoch 20/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 454ms/step - acc: 0.7818 - loss: 0.6567 - val_acc: 0.7529 - val_loss: 0.7772\n",
            "Epoch 21/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 458ms/step - acc: 0.7874 - loss: 0.6428 - val_acc: 0.7427 - val_loss: 0.7875\n",
            "Epoch 22/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 462ms/step - acc: 0.7950 - loss: 0.6310 - val_acc: 0.7633 - val_loss: 0.7562\n",
            "Epoch 23/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 475ms/step - acc: 0.7987 - loss: 0.6069 - val_acc: 0.7787 - val_loss: 0.7276\n",
            "Epoch 24/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 459ms/step - acc: 0.8068 - loss: 0.5882 - val_acc: 0.7574 - val_loss: 0.7662\n",
            "Epoch 25/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 463ms/step - acc: 0.8058 - loss: 0.5923 - val_acc: 0.7486 - val_loss: 0.7820\n",
            "Epoch 26/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 462ms/step - acc: 0.8125 - loss: 0.5822 - val_acc: 0.7371 - val_loss: 0.7740\n",
            "Epoch 27/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 466ms/step - acc: 0.8163 - loss: 0.5635 - val_acc: 0.8070 - val_loss: 0.6014\n",
            "Epoch 28/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 462ms/step - acc: 0.8171 - loss: 0.5486 - val_acc: 0.7900 - val_loss: 0.6776\n",
            "Epoch 29/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 460ms/step - acc: 0.8220 - loss: 0.5443 - val_acc: 0.7892 - val_loss: 0.6814\n",
            "Epoch 30/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 455ms/step - acc: 0.8227 - loss: 0.5325 - val_acc: 0.7413 - val_loss: 0.8274\n",
            "Epoch 31/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 461ms/step - acc: 0.8288 - loss: 0.5247 - val_acc: 0.7843 - val_loss: 0.6505\n",
            "Epoch 32/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 469ms/step - acc: 0.8295 - loss: 0.5212 - val_acc: 0.7819 - val_loss: 0.6748\n",
            "Epoch 33/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 458ms/step - acc: 0.8352 - loss: 0.5127 - val_acc: 0.7926 - val_loss: 0.6287\n",
            "Epoch 34/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 457ms/step - acc: 0.8390 - loss: 0.4874 - val_acc: 0.7592 - val_loss: 0.7311\n",
            "Epoch 35/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 462ms/step - acc: 0.8373 - loss: 0.5052 - val_acc: 0.7943 - val_loss: 0.6147\n",
            "Epoch 36/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 455ms/step - acc: 0.8459 - loss: 0.4808 - val_acc: 0.7291 - val_loss: 0.8099\n",
            "Epoch 37/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 459ms/step - acc: 0.8416 - loss: 0.4790 - val_acc: 0.8224 - val_loss: 0.5708\n",
            "Epoch 38/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 464ms/step - acc: 0.8466 - loss: 0.4611 - val_acc: 0.8108 - val_loss: 0.5823\n",
            "Epoch 39/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 455ms/step - acc: 0.8489 - loss: 0.4543 - val_acc: 0.7892 - val_loss: 0.6259\n",
            "Epoch 40/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 441ms/step - acc: 0.8483 - loss: 0.4570 - val_acc: 0.7970 - val_loss: 0.6003\n",
            "Epoch 41/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 447ms/step - acc: 0.8534 - loss: 0.4485 - val_acc: 0.7994 - val_loss: 0.5859\n",
            "Epoch 42/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 451ms/step - acc: 0.8517 - loss: 0.4478 - val_acc: 0.7916 - val_loss: 0.6212\n",
            "Epoch 43/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 447ms/step - acc: 0.8565 - loss: 0.4317 - val_acc: 0.7736 - val_loss: 0.6735\n",
            "Epoch 44/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 460ms/step - acc: 0.8585 - loss: 0.4263 - val_acc: 0.8115 - val_loss: 0.5662\n",
            "Epoch 45/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 458ms/step - acc: 0.8554 - loss: 0.4362 - val_acc: 0.8105 - val_loss: 0.5852\n",
            "Epoch 46/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 456ms/step - acc: 0.8658 - loss: 0.4132 - val_acc: 0.8227 - val_loss: 0.5331\n",
            "Epoch 47/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 455ms/step - acc: 0.8620 - loss: 0.4190 - val_acc: 0.8246 - val_loss: 0.5308\n",
            "Epoch 48/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 451ms/step - acc: 0.8660 - loss: 0.4032 - val_acc: 0.7861 - val_loss: 0.6728\n",
            "Epoch 49/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 456ms/step - acc: 0.8674 - loss: 0.4014 - val_acc: 0.8356 - val_loss: 0.5078\n",
            "Epoch 50/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 458ms/step - acc: 0.8696 - loss: 0.3950 - val_acc: 0.8253 - val_loss: 0.5230\n",
            "Epoch 51/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 461ms/step - acc: 0.8699 - loss: 0.3983 - val_acc: 0.7999 - val_loss: 0.5922\n",
            "Epoch 52/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 454ms/step - acc: 0.8689 - loss: 0.3932 - val_acc: 0.8196 - val_loss: 0.5370\n",
            "Epoch 53/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 456ms/step - acc: 0.8718 - loss: 0.3923 - val_acc: 0.8073 - val_loss: 0.5748\n",
            "Epoch 54/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 458ms/step - acc: 0.8751 - loss: 0.3789 - val_acc: 0.8158 - val_loss: 0.5616\n",
            "Epoch 55/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 456ms/step - acc: 0.8708 - loss: 0.3904 - val_acc: 0.8144 - val_loss: 0.5671\n",
            "Epoch 56/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 454ms/step - acc: 0.8771 - loss: 0.3731 - val_acc: 0.8310 - val_loss: 0.5178\n",
            "Epoch 57/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 454ms/step - acc: 0.8797 - loss: 0.3690 - val_acc: 0.8247 - val_loss: 0.5391\n",
            "Epoch 58/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 449ms/step - acc: 0.8768 - loss: 0.3702 - val_acc: 0.8393 - val_loss: 0.5059\n",
            "Epoch 59/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 453ms/step - acc: 0.8799 - loss: 0.3584 - val_acc: 0.8147 - val_loss: 0.5408\n",
            "Epoch 60/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 443ms/step - acc: 0.8838 - loss: 0.3504 - val_acc: 0.8376 - val_loss: 0.5100\n",
            "Epoch 61/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 466ms/step - acc: 0.8815 - loss: 0.3581 - val_acc: 0.8446 - val_loss: 0.4674\n",
            "Epoch 62/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 450ms/step - acc: 0.8830 - loss: 0.3475 - val_acc: 0.8038 - val_loss: 0.6137\n",
            "Epoch 63/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 456ms/step - acc: 0.8798 - loss: 0.3552 - val_acc: 0.8385 - val_loss: 0.4923\n",
            "Epoch 64/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 446ms/step - acc: 0.8841 - loss: 0.3479 - val_acc: 0.7951 - val_loss: 0.6118\n",
            "Epoch 65/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 459ms/step - acc: 0.8866 - loss: 0.3620 - val_acc: 0.8302 - val_loss: 0.5006\n",
            "Epoch 66/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 461ms/step - acc: 0.8850 - loss: 0.3389 - val_acc: 0.8371 - val_loss: 0.5176\n",
            "Epoch 67/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 461ms/step - acc: 0.8909 - loss: 0.3332 - val_acc: 0.8300 - val_loss: 0.5068\n",
            "Epoch 68/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 445ms/step - acc: 0.8862 - loss: 0.3386 - val_acc: 0.8425 - val_loss: 0.5024\n",
            "Epoch 69/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 451ms/step - acc: 0.8921 - loss: 0.3265 - val_acc: 0.8334 - val_loss: 0.4994\n",
            "Epoch 70/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 456ms/step - acc: 0.8906 - loss: 0.3268 - val_acc: 0.8490 - val_loss: 0.4661\n",
            "Epoch 71/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 453ms/step - acc: 0.8931 - loss: 0.3298 - val_acc: 0.8519 - val_loss: 0.4522\n",
            "Epoch 72/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 449ms/step - acc: 0.8922 - loss: 0.3208 - val_acc: 0.7938 - val_loss: 0.6283\n",
            "Epoch 73/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 455ms/step - acc: 0.8945 - loss: 0.3197 - val_acc: 0.8407 - val_loss: 0.4808\n",
            "Epoch 74/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 454ms/step - acc: 0.8931 - loss: 0.3179 - val_acc: 0.8334 - val_loss: 0.5092\n",
            "Epoch 75/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 451ms/step - acc: 0.8950 - loss: 0.3122 - val_acc: 0.8437 - val_loss: 0.4615\n",
            "Epoch 76/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 447ms/step - acc: 0.8925 - loss: 0.3245 - val_acc: 0.8341 - val_loss: 0.5007\n",
            "Epoch 77/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 449ms/step - acc: 0.8971 - loss: 0.3155 - val_acc: 0.8456 - val_loss: 0.4591\n",
            "Epoch 78/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 452ms/step - acc: 0.8980 - loss: 0.3082 - val_acc: 0.8393 - val_loss: 0.4791\n",
            "Epoch 79/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 444ms/step - acc: 0.8991 - loss: 0.3052 - val_acc: 0.8056 - val_loss: 0.5955\n",
            "Epoch 80/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 447ms/step - acc: 0.8995 - loss: 0.3045 - val_acc: 0.8500 - val_loss: 0.4541\n",
            "Epoch 81/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 455ms/step - acc: 0.8993 - loss: 0.3040 - val_acc: 0.8431 - val_loss: 0.4839\n",
            "Epoch 82/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 450ms/step - acc: 0.8994 - loss: 0.2979 - val_acc: 0.8392 - val_loss: 0.4928\n",
            "Epoch 83/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 446ms/step - acc: 0.9018 - loss: 0.2962 - val_acc: 0.8416 - val_loss: 0.4685\n",
            "Epoch 84/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 453ms/step - acc: 0.9010 - loss: 0.2914 - val_acc: 0.8333 - val_loss: 0.4905\n",
            "Epoch 85/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 451ms/step - acc: 0.9021 - loss: 0.2918 - val_acc: 0.8550 - val_loss: 0.4281\n",
            "Epoch 86/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 447ms/step - acc: 0.9032 - loss: 0.2900 - val_acc: 0.8631 - val_loss: 0.4206\n",
            "Epoch 87/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 450ms/step - acc: 0.9025 - loss: 0.2897 - val_acc: 0.8494 - val_loss: 0.4380\n",
            "Epoch 88/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 452ms/step - acc: 0.9060 - loss: 0.2753 - val_acc: 0.8625 - val_loss: 0.4216\n",
            "Epoch 89/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 454ms/step - acc: 0.9089 - loss: 0.2809 - val_acc: 0.8550 - val_loss: 0.4261\n",
            "Epoch 90/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 449ms/step - acc: 0.9049 - loss: 0.2861 - val_acc: 0.8616 - val_loss: 0.4245\n",
            "Epoch 91/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 456ms/step - acc: 0.9088 - loss: 0.2740 - val_acc: 0.8579 - val_loss: 0.4304\n",
            "Epoch 92/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 455ms/step - acc: 0.9092 - loss: 0.2729 - val_acc: 0.8468 - val_loss: 0.4472\n",
            "Epoch 93/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 452ms/step - acc: 0.9080 - loss: 0.2728 - val_acc: 0.8539 - val_loss: 0.4422\n",
            "Epoch 94/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 444ms/step - acc: 0.9130 - loss: 0.2642 - val_acc: 0.8606 - val_loss: 0.4236\n",
            "Epoch 95/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 453ms/step - acc: 0.9092 - loss: 0.2732 - val_acc: 0.8582 - val_loss: 0.4460\n",
            "Epoch 96/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 449ms/step - acc: 0.9109 - loss: 0.2665 - val_acc: 0.8131 - val_loss: 0.5646\n",
            "Epoch 97/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 455ms/step - acc: 0.9106 - loss: 0.2628 - val_acc: 0.8634 - val_loss: 0.4277\n",
            "Epoch 98/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 447ms/step - acc: 0.9112 - loss: 0.2700 - val_acc: 0.8631 - val_loss: 0.4246\n",
            "Epoch 99/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 461ms/step - acc: 0.9100 - loss: 0.2670 - val_acc: 0.8630 - val_loss: 0.4054\n",
            "Epoch 100/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 460ms/step - acc: 0.9121 - loss: 0.2675 - val_acc: 0.8393 - val_loss: 0.4645\n",
            "Epoch 101/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 450ms/step - acc: 0.9127 - loss: 0.2642 - val_acc: 0.8658 - val_loss: 0.4203\n",
            "Epoch 102/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 446ms/step - acc: 0.9158 - loss: 0.2601 - val_acc: 0.8380 - val_loss: 0.4678\n",
            "Epoch 103/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 456ms/step - acc: 0.9149 - loss: 0.2562 - val_acc: 0.8476 - val_loss: 0.4467\n",
            "Epoch 104/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 451ms/step - acc: 0.9115 - loss: 0.2568 - val_acc: 0.8580 - val_loss: 0.4275\n",
            "Epoch 105/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 449ms/step - acc: 0.9151 - loss: 0.2469 - val_acc: 0.8599 - val_loss: 0.4300\n",
            "Epoch 106/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 448ms/step - acc: 0.9127 - loss: 0.2580 - val_acc: 0.8633 - val_loss: 0.4171\n",
            "Epoch 107/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 454ms/step - acc: 0.9160 - loss: 0.2495 - val_acc: 0.8571 - val_loss: 0.4228\n",
            "Epoch 108/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 455ms/step - acc: 0.9160 - loss: 0.2476 - val_acc: 0.8597 - val_loss: 0.4357\n",
            "Epoch 109/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 445ms/step - acc: 0.9133 - loss: 0.2524 - val_acc: 0.8322 - val_loss: 0.5397\n",
            "Epoch 110/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 454ms/step - acc: 0.9171 - loss: 0.2474 - val_acc: 0.8657 - val_loss: 0.4133\n",
            "Epoch 111/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 471ms/step - acc: 0.9169 - loss: 0.2495 - val_acc: 0.8460 - val_loss: 0.4608\n",
            "Epoch 112/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 459ms/step - acc: 0.9174 - loss: 0.2432 - val_acc: 0.8605 - val_loss: 0.4234\n",
            "Epoch 113/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 459ms/step - acc: 0.9199 - loss: 0.2375 - val_acc: 0.8523 - val_loss: 0.4390\n",
            "Epoch 114/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 448ms/step - acc: 0.9182 - loss: 0.2477 - val_acc: 0.8628 - val_loss: 0.4135\n",
            "Epoch 115/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 463ms/step - acc: 0.9170 - loss: 0.2425 - val_acc: 0.8362 - val_loss: 0.4859\n",
            "Epoch 116/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 454ms/step - acc: 0.9202 - loss: 0.2407 - val_acc: 0.8619 - val_loss: 0.4214\n",
            "Epoch 117/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 458ms/step - acc: 0.9209 - loss: 0.2444 - val_acc: 0.8598 - val_loss: 0.4338\n",
            "Epoch 118/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 452ms/step - acc: 0.9204 - loss: 0.2402 - val_acc: 0.8572 - val_loss: 0.4461\n",
            "Epoch 119/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 458ms/step - acc: 0.9219 - loss: 0.2298 - val_acc: 0.8663 - val_loss: 0.4057\n",
            "Epoch 120/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 475ms/step - acc: 0.9205 - loss: 0.2350 - val_acc: 0.8603 - val_loss: 0.4319\n",
            "Epoch 121/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 478ms/step - acc: 0.9214 - loss: 0.2318 - val_acc: 0.8392 - val_loss: 0.4838\n",
            "Epoch 122/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 456ms/step - acc: 0.9227 - loss: 0.2335 - val_acc: 0.8286 - val_loss: 0.5089\n",
            "Epoch 123/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 452ms/step - acc: 0.9214 - loss: 0.2429 - val_acc: 0.8625 - val_loss: 0.4153\n",
            "Epoch 124/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 455ms/step - acc: 0.9232 - loss: 0.2296 - val_acc: 0.8623 - val_loss: 0.3991\n",
            "Epoch 125/125\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 459ms/step - acc: 0.9191 - loss: 0.2299 - val_acc: 0.8710 - val_loss: 0.3982\n"
          ]
        }
      ],
      "source": [
        "#improvemnet:changing the epoches to 125\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('shape of x_train: ' + str(x_train.shape))\n",
        "print('shape of y_train: ' + str(y_train.shape))\n",
        "print('shape of x_test: ' + str(x_test.shape))\n",
        "print('shape of y_test: ' + str(y_test.shape))\n",
        "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "def to_one_hot(y, num_class=10):\n",
        "\n",
        "    to_one_hot = to_categorical(y, 10)\n",
        "    return to_one_hot\n",
        "\n",
        "y_train_vec = to_one_hot(y_train)\n",
        "y_test_vec = to_one_hot(y_test)\n",
        "\n",
        "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
        "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
        "\n",
        "print(y_train[0])\n",
        "print(y_train_vec[0])\n",
        "\n",
        "rand_indices = numpy.random.permutation(50000)\n",
        "train_indices = rand_indices[0:40000]\n",
        "valid_indices = rand_indices[40000:50000]\n",
        "\n",
        "x_val = x_train[valid_indices, :]\n",
        "y_val = y_train_vec[valid_indices, :]\n",
        "\n",
        "x_tr = x_train[train_indices, :]\n",
        "y_tr = y_train_vec[train_indices, :]\n",
        "\n",
        "print('Shape of x_tr: ' + str(x_tr.shape))\n",
        "print('Shape of y_tr: ' + str(y_tr.shape))\n",
        "print('Shape of x_val: ' + str(x_val.shape))\n",
        "print('Shape of y_val: ' + str(y_val.shape))\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# Data augmentation\n",
        "data_generator = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range=15,\n",
        "\n",
        "    width_shift_range=0.12,\n",
        "\n",
        "    height_shift_range=0.12,\n",
        "\n",
        "    horizontal_flip=True,\n",
        "\n",
        "    zoom_range=0.1,\n",
        "\n",
        "    brightness_range=[0.9,1.1],\n",
        "\n",
        "    shear_range=10,\n",
        "\n",
        "    channel_shift_range=0.1,\n",
        ")\n",
        "\n",
        "val_generator = data_generator.flow(x_val, y_val, batch_size = 100)\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,BatchNormalization, Dropout\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "from keras import optimizers\n",
        "\n",
        "learning_rate = 0.001#(after tunning)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=learning_rate),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(data_generator.flow(x_tr, y_tr, batch_size=400),\n",
        "                    epochs=125,\n",
        "                    validation_data=val_generator,\n",
        "                    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "gzRxRJ4QEyC2",
        "outputId": "be0f8a93-fc70-4512-967a-2d5fe508d299"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDy2gz8fEyC3"
      },
      "source": [
        "## 3. Train (again) and evaluate the model\n",
        "\n",
        "- To this end, you have found the \"best\" hyper-parameters.\n",
        "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
        "- Evaluate your model on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg-hMqR-EyC3"
      },
      "source": [
        "### 3.1. Train the model on the entire training set\n",
        "\n",
        "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhB1TIRcEyC3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "511a750e-b256-498a-f34b-5755d21609e9"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "shape of x_train: (50000, 32, 32, 3)\n",
            "shape of y_train: (50000, 1)\n",
            "shape of x_test: (10000, 32, 32, 3)\n",
            "shape of y_test: (10000, 1)\n",
            "number of classes: 10\n",
            "Shape of y_train_vec: (50000, 10)\n",
            "Shape of y_test_vec: (10000, 10)\n",
            "[6]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,250</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m590,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m590,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m525,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m10,250\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,352,810</span> (31.86 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,352,810\u001b[0m (31.86 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,349,034</span> (31.85 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,349,034\u001b[0m (31.85 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,776</span> (14.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,776\u001b[0m (14.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 499ms/step - acc: 0.1359 - loss: 3.1478\n",
            "Epoch 2/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 431ms/step - acc: 0.2179 - loss: 2.1868\n",
            "Epoch 3/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 404ms/step - acc: 0.3500 - loss: 1.7155\n",
            "Epoch 4/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 390ms/step - acc: 0.4703 - loss: 1.4523\n",
            "Epoch 5/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 388ms/step - acc: 0.5519 - loss: 1.2688\n",
            "Epoch 6/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 386ms/step - acc: 0.5993 - loss: 1.1516\n",
            "Epoch 7/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 391ms/step - acc: 0.6305 - loss: 1.0747\n",
            "Epoch 8/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 391ms/step - acc: 0.6539 - loss: 1.0031\n",
            "Epoch 9/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 391ms/step - acc: 0.6826 - loss: 0.9332\n",
            "Epoch 10/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 385ms/step - acc: 0.6999 - loss: 0.8849\n",
            "Epoch 11/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 384ms/step - acc: 0.7108 - loss: 0.8624\n",
            "Epoch 12/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 390ms/step - acc: 0.7288 - loss: 0.8055\n",
            "Epoch 13/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 386ms/step - acc: 0.7431 - loss: 0.7738\n",
            "Epoch 14/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 380ms/step - acc: 0.7556 - loss: 0.7352\n",
            "Epoch 15/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 393ms/step - acc: 0.7592 - loss: 0.7197\n",
            "Epoch 16/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 385ms/step - acc: 0.7737 - loss: 0.6809\n",
            "Epoch 17/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 383ms/step - acc: 0.7826 - loss: 0.6661\n",
            "Epoch 18/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 388ms/step - acc: 0.7831 - loss: 0.6556\n",
            "Epoch 19/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 386ms/step - acc: 0.7930 - loss: 0.6370\n",
            "Epoch 20/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 388ms/step - acc: 0.8001 - loss: 0.6098\n",
            "Epoch 21/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 391ms/step - acc: 0.8045 - loss: 0.5891\n",
            "Epoch 22/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 383ms/step - acc: 0.8054 - loss: 0.5932\n",
            "Epoch 23/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 399ms/step - acc: 0.8152 - loss: 0.5670\n",
            "Epoch 24/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 384ms/step - acc: 0.8180 - loss: 0.5580\n",
            "Epoch 25/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 387ms/step - acc: 0.8200 - loss: 0.5488\n",
            "Epoch 26/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 389ms/step - acc: 0.8229 - loss: 0.5362\n",
            "Epoch 27/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 386ms/step - acc: 0.8278 - loss: 0.5254\n",
            "Epoch 28/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 403ms/step - acc: 0.8285 - loss: 0.5165\n",
            "Epoch 29/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 386ms/step - acc: 0.8291 - loss: 0.5163\n",
            "Epoch 30/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 392ms/step - acc: 0.8395 - loss: 0.4909\n",
            "Epoch 31/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 394ms/step - acc: 0.8401 - loss: 0.4860\n",
            "Epoch 32/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 386ms/step - acc: 0.8421 - loss: 0.4764\n",
            "Epoch 33/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 389ms/step - acc: 0.8438 - loss: 0.4761\n",
            "Epoch 34/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 384ms/step - acc: 0.8495 - loss: 0.4568\n",
            "Epoch 35/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 393ms/step - acc: 0.8503 - loss: 0.4577\n",
            "Epoch 36/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 397ms/step - acc: 0.8511 - loss: 0.4554\n",
            "Epoch 37/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 396ms/step - acc: 0.8544 - loss: 0.4412\n",
            "Epoch 38/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 386ms/step - acc: 0.8551 - loss: 0.4434\n",
            "Epoch 39/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 386ms/step - acc: 0.8562 - loss: 0.4435\n",
            "Epoch 40/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 389ms/step - acc: 0.8594 - loss: 0.4315\n",
            "Epoch 41/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 387ms/step - acc: 0.8612 - loss: 0.4257\n",
            "Epoch 42/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 391ms/step - acc: 0.8631 - loss: 0.4139\n",
            "Epoch 43/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 388ms/step - acc: 0.8653 - loss: 0.4074\n",
            "Epoch 44/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 409ms/step - acc: 0.8699 - loss: 0.3961\n",
            "Epoch 45/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 385ms/step - acc: 0.8666 - loss: 0.4036\n",
            "Epoch 46/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 381ms/step - acc: 0.8643 - loss: 0.4142\n",
            "Epoch 47/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 386ms/step - acc: 0.8692 - loss: 0.3904\n",
            "Epoch 48/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 381ms/step - acc: 0.8727 - loss: 0.3864\n",
            "Epoch 49/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 384ms/step - acc: 0.8733 - loss: 0.3778\n",
            "Epoch 50/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 387ms/step - acc: 0.8722 - loss: 0.3854\n",
            "Epoch 51/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 383ms/step - acc: 0.8701 - loss: 0.3835\n",
            "Epoch 52/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 395ms/step - acc: 0.8804 - loss: 0.3642\n",
            "Epoch 53/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 380ms/step - acc: 0.8772 - loss: 0.3674\n",
            "Epoch 54/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 383ms/step - acc: 0.8790 - loss: 0.3711\n",
            "Epoch 55/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 386ms/step - acc: 0.8778 - loss: 0.3642\n",
            "Epoch 56/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 381ms/step - acc: 0.8801 - loss: 0.3605\n",
            "Epoch 57/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 385ms/step - acc: 0.8817 - loss: 0.3490\n",
            "Epoch 58/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 383ms/step - acc: 0.8843 - loss: 0.3533\n",
            "Epoch 59/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 385ms/step - acc: 0.8847 - loss: 0.3458\n",
            "Epoch 60/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 398ms/step - acc: 0.8862 - loss: 0.3388\n",
            "Epoch 61/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 384ms/step - acc: 0.8847 - loss: 0.3471\n",
            "Epoch 62/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 381ms/step - acc: 0.8853 - loss: 0.3354\n",
            "Epoch 63/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 389ms/step - acc: 0.8893 - loss: 0.3300\n",
            "Epoch 64/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 379ms/step - acc: 0.8899 - loss: 0.3275\n",
            "Epoch 65/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 398ms/step - acc: 0.8893 - loss: 0.3323\n",
            "Epoch 66/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 382ms/step - acc: 0.8908 - loss: 0.3282\n",
            "Epoch 67/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 382ms/step - acc: 0.8890 - loss: 0.3269\n",
            "Epoch 68/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 389ms/step - acc: 0.8921 - loss: 0.3221\n",
            "Epoch 69/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 385ms/step - acc: 0.8931 - loss: 0.3183\n",
            "Epoch 70/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 391ms/step - acc: 0.8946 - loss: 0.3134\n",
            "Epoch 71/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 383ms/step - acc: 0.9001 - loss: 0.3068\n",
            "Epoch 72/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 386ms/step - acc: 0.8951 - loss: 0.3111\n",
            "Epoch 73/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 401ms/step - acc: 0.8962 - loss: 0.3119\n",
            "Epoch 74/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 383ms/step - acc: 0.8987 - loss: 0.3010\n",
            "Epoch 75/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 392ms/step - acc: 0.8967 - loss: 0.3061\n",
            "Epoch 76/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 387ms/step - acc: 0.8977 - loss: 0.3097\n",
            "Epoch 77/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 388ms/step - acc: 0.9006 - loss: 0.2980\n",
            "Epoch 78/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 395ms/step - acc: 0.8984 - loss: 0.3027\n",
            "Epoch 79/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 387ms/step - acc: 0.9009 - loss: 0.2954\n",
            "Epoch 80/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 397ms/step - acc: 0.9005 - loss: 0.2966\n",
            "Epoch 81/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 385ms/step - acc: 0.9028 - loss: 0.2909\n",
            "Epoch 82/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 393ms/step - acc: 0.9033 - loss: 0.2913\n",
            "Epoch 83/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 385ms/step - acc: 0.9037 - loss: 0.2866\n",
            "Epoch 84/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 381ms/step - acc: 0.9067 - loss: 0.2837\n",
            "Epoch 85/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 389ms/step - acc: 0.9022 - loss: 0.2860\n",
            "Epoch 86/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 392ms/step - acc: 0.9072 - loss: 0.2792\n",
            "Epoch 87/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 386ms/step - acc: 0.9048 - loss: 0.2799\n",
            "Epoch 88/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 384ms/step - acc: 0.9090 - loss: 0.2675\n",
            "Epoch 89/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 382ms/step - acc: 0.9097 - loss: 0.2756\n",
            "Epoch 90/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 389ms/step - acc: 0.9079 - loss: 0.2793\n",
            "Epoch 91/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 390ms/step - acc: 0.9115 - loss: 0.2624\n",
            "Epoch 92/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 394ms/step - acc: 0.9068 - loss: 0.2784\n",
            "Epoch 93/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 389ms/step - acc: 0.9140 - loss: 0.2591\n",
            "Epoch 94/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 387ms/step - acc: 0.9119 - loss: 0.2618\n",
            "Epoch 95/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 383ms/step - acc: 0.9100 - loss: 0.2642\n",
            "Epoch 96/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 390ms/step - acc: 0.9120 - loss: 0.2640\n",
            "Epoch 97/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 384ms/step - acc: 0.9125 - loss: 0.2599\n",
            "Epoch 98/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 391ms/step - acc: 0.9137 - loss: 0.2555\n",
            "Epoch 99/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 396ms/step - acc: 0.9138 - loss: 0.2621\n",
            "Epoch 100/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 380ms/step - acc: 0.9117 - loss: 0.2545\n",
            "Epoch 101/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 387ms/step - acc: 0.9141 - loss: 0.2519\n",
            "Epoch 102/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 383ms/step - acc: 0.9153 - loss: 0.2505\n",
            "Epoch 103/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 388ms/step - acc: 0.9166 - loss: 0.2463\n",
            "Epoch 104/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 381ms/step - acc: 0.9156 - loss: 0.2507\n",
            "Epoch 105/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 382ms/step - acc: 0.9166 - loss: 0.2493\n",
            "Epoch 106/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 391ms/step - acc: 0.9150 - loss: 0.2480\n",
            "Epoch 107/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 398ms/step - acc: 0.9144 - loss: 0.2567\n",
            "Epoch 108/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 386ms/step - acc: 0.9199 - loss: 0.2428\n",
            "Epoch 109/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 381ms/step - acc: 0.9176 - loss: 0.2443\n",
            "Epoch 110/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 380ms/step - acc: 0.9164 - loss: 0.2473\n",
            "Epoch 111/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 386ms/step - acc: 0.9198 - loss: 0.2396\n",
            "Epoch 112/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 387ms/step - acc: 0.9217 - loss: 0.2346\n",
            "Epoch 113/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 379ms/step - acc: 0.9216 - loss: 0.2351\n",
            "Epoch 114/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 387ms/step - acc: 0.9206 - loss: 0.2409\n",
            "Epoch 115/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 382ms/step - acc: 0.9182 - loss: 0.2369\n",
            "Epoch 116/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 383ms/step - acc: 0.9180 - loss: 0.2359\n",
            "Epoch 117/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 385ms/step - acc: 0.9210 - loss: 0.2342\n",
            "Epoch 118/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 382ms/step - acc: 0.9247 - loss: 0.2265\n",
            "Epoch 119/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 392ms/step - acc: 0.9211 - loss: 0.2295\n",
            "Epoch 120/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 398ms/step - acc: 0.9208 - loss: 0.2351\n",
            "Epoch 121/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 390ms/step - acc: 0.9221 - loss: 0.2274\n",
            "Epoch 122/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 381ms/step - acc: 0.9206 - loss: 0.2322\n",
            "Epoch 123/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 381ms/step - acc: 0.9234 - loss: 0.2239\n",
            "Epoch 124/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 390ms/step - acc: 0.9224 - loss: 0.2298\n",
            "Epoch 125/125\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 382ms/step - acc: 0.9237 - loss: 0.2222\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - acc: 0.1956 - loss: 440.4521\n",
            "loss = 428.8604431152344\n",
            "accuracy = 0.20080000162124634\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('shape of x_train: ' + str(x_train.shape))\n",
        "print('shape of y_train: ' + str(y_train.shape))\n",
        "print('shape of x_test: ' + str(x_test.shape))\n",
        "print('shape of y_test: ' + str(y_test.shape))\n",
        "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "def to_one_hot(y, num_class=10):\n",
        "\n",
        "    to_one_hot = to_categorical(y, 10)\n",
        "    return to_one_hot\n",
        "\n",
        "y_train_vec = to_one_hot(y_train)\n",
        "y_test_vec = to_one_hot(y_test)\n",
        "\n",
        "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
        "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
        "\n",
        "print(y_train[0])\n",
        "print(y_train_vec[0])\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# Data augmentation\n",
        "data_generator = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range=15,\n",
        "\n",
        "    width_shift_range=0.12,\n",
        "\n",
        "    height_shift_range=0.12,\n",
        "\n",
        "    horizontal_flip=True,\n",
        "\n",
        "    zoom_range=0.1,\n",
        "\n",
        "    brightness_range=[0.9,1.1],\n",
        "\n",
        "    shear_range=10,\n",
        "\n",
        "    channel_shift_range=0.1,\n",
        ")\n",
        "\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,BatchNormalization, Dropout\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#<Compile your model again (using the same hyper-parameters)>\n",
        "from keras import optimizers\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=learning_rate),\n",
        "              metrics=['acc'])\n",
        "\n",
        "#3.1. Train the model on the entire training set\n",
        "\n",
        "#<Use (x_train, y_train_vec) instead of (x_tr, y_tr)>\n",
        "#<Do NOT use the validation_data option (because now you do not have validation data)>\n",
        "history = model.fit(data_generator.flow(x_train, y_train_vec, batch_size=480),\n",
        "                    epochs=125,\n",
        "                    )\n",
        "\n",
        "#3.2. Evaluate the model on the test set(wrong code, ignore)\n",
        "\n",
        "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
        "print('loss = ' + str(loss_and_acc[0]))\n",
        "print('accuracy = ' + str(loss_and_acc[1]))#(wrong code)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2. Evaluate the model on the test set\n",
        "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
      ],
      "metadata": {
        "id": "nd4fdc82wZIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = x_test / 255.0\n",
        "y_test_vec = y_test_vec / 255.0\n",
        "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
        "print('loss = ' + str(loss_and_acc[0]))\n",
        "print('accuracy = ' + str(loss_and_acc[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1c0alB9wZsy",
        "outputId": "f3c9a16b-d075-4318-847b-a70c8334c748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.8800 - loss: 0.0015\n",
            "loss = 0.0014384069945663214\n",
            "accuracy = 0.8812000155448914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examine the Results\n",
        "Training accaracy : 92.37%\n",
        "Validation accuracy: 87.10%\n",
        "Test accaracy : 88.12%"
      ],
      "metadata": {
        "id": "8yzIQB0t1vGt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is about image recognizaiton CNN by VGG16.\n",
        "During this trainning process, data augmentation(rescale,flip,rotaton and so on), batch normalization, dropout, adjusting the learning rate, changing the number of epoch have been applied to improve the accaracy."
      ],
      "metadata": {
        "id": "FdeBW-Ep8cDl"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}